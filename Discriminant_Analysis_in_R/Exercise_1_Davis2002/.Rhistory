knitr::opts_chunk$set(echo = TRUE)
data.raw <- read.csv("arenas.csv", header = T, skip = ",")
View(data.raw)
data.raw <- read.csv("arenas.csv", header = T, skip = ",")
str(data.raw)
mydata <- na.omit(data.raw)
View(mydata)
is.na(mydata)
View(mydata)
??test.wilk
??test_wilks
??manova
group <- as.factor(mydata[, 3])
x <- as.matrix(mydata[, 1:2])
# Using the default interface, classical test
Wilks.test(x, grouping=group, method="c")
group
Y
Y <- as.matrix(mydata[, 1:2])
Y
result<-manova(Y ~ grupo)
test_Wilks<-summary(result, test = "Wilks")
result<-manova(Y ~ group)
test_Wilks<-summary(result, test = "Wilks")
test_Wilks
View(data.raw)
result
??lda
predict.data <- data.raw[which(data.raw$group == "NA"), ]
View(predict.data)
predict.data <- data.raw[which(data.raw$group = "NA"), ]
View(data.raw)
predict.data <- data.raw[which(data.raw$Group == "NA"), ]
View(predict.data)
predict.data <- data.raw[which(data.raw$Group == NA), ]
predict.data <- data.raw[which(data.raw$Group == "NA"), ]
library(data.table)
install.packages("data.table")
knitr::opts_chunk$set(echo = TRUE)
data.raw <- read.csv("arenas.csv", header = T, skip = ",")
str(data.raw)                   # estructura del dataframe
mydata <- na.omit(data.raw)     # omite filas con NA's
predict.data <- DT[data.raw$Group = "NA"]
predict.data <- DT[data.raw$Group = "NA", ]
library(dplyr)
predict.data <- dplyr::filter(data.raw, Group=="NA")
data.raw <- read.csv("arenas.csv", header = T, skip = ",")
str(data.raw)                   # estructura del dataframe
mydata <- na.omit(data.raw)     # omite filas con NA's
predict.data <- dplyr::filter(data.raw, Group=="NA")
View(predict.data)
arenas <- read.csv("arenas.csv", header = T, skip = ",")
str(arenas)                   # estructura del dataframe
newcases <- read.csv("newcases.csv", header = T, skip = ",")
str(newcases)                # estructura del dataframe
arenas <- read.csv("arenas.csv", header = T, skip = ",")
str(arenas)                   # estructura del dataframe
clasificar <- read.csv("clasificar.csv", header = T, skip = ",")
str(clasificar)                # estructura del dataframe
View(arenas)
View(clasificar)
library(MASS)
help("lda")
group <- as.factor(arenas[, 3])
Y <- as.matrix(arenas[, 1:2])
result <- manova(Y ~ group)
test_Wilks <- summary(result, test = "Wilks")
print("Prueba de igualdad de medias de los grupos: Test de Wilks")
print("                                                         ")
print(test_Wilks)
print("                                                         ")
print("Si Pr<0.05, habrá diferencias entre las medias y el analisis discriminante es aplicable")
poder_discrim <- summary.aov(result)
print("                                                         ")
print("?Qué variable(s) tiene mayor poder discriminatorio?")
print("                                                         ")
print("La variable que mayor poder discriminante tiene es la que tiene menor Pr o mayor F value")
print("                                                         ")
print(poder_discrim)
print("                                                         ")
fit.lda <- lda(group ~ ., data = arenas)
arenas <- read.csv("arenas.csv", header = T, skip = ",")
str(arenas)                   # estructura del dataframe
X <- arenas[, -3]
clasificar <- read.csv("clasificar.csv", header = T, skip = ",")
str(clasificar)                # estructura del dataframe
View(clasificar)
str(X)
clasificar <- as.factor(clasificar$Group)
str(clasificar)                # estructura del dataframe
clasificar <- read.csv("clasificar.csv", header = T, skip = ",")
clasificar <- as.factor(clasificar[, 3])
str(clasificar)                # estructura del dataframe
packrat::init(options = list(auto.snapshot = TRUE))
knitr::opts_chunk$set(echo = TRUE)
library(caret)
??ldahist
packrat::init(options = list(auto.snapshot = TRUE))
knitr::opts_chunk$set(echo = TRUE)
library(MASS)              # lda, ldahist functions
library(caret)             # confusionMatrix, train functions
library(klaR)              # partimat function (final plot)
library(kableExtra)
arenas <- read.csv("arenas.csv", header = T, skip = ",")
arenas$Group <- as.factor(arenas$Group)
str(arenas)                   # estructura del dataframe
X <- arenas[, -3]
clasificar <- read.csv("clasificar.csv", header = T, skip = ",")
clasificar$Group <- as.factor(clasificar$Group)
str(clasificar)                # estructura del dataframe
View(arenas)
index = createDataPartition(y=arenas$Group, p=0.8, list=FALSE)
train = iris[index,]
test = iris[-index,]
dim(train)
dim(test)
View(train)
index = createDataPartition(y=arenas$Group, p=0.8, list=FALSE)
train = arenas[index,]
test = arenas[-index,]
dim(train)
dim(test)
fitControl <- trainControl(# 10-fold CV
method = "cv",
number = 10,           # number of folds
allowParallel = TRUE   # Parallel processing
)
# LDA
fit.lda.cv <- train(Group ~ .,
data = train,
preProc = c("center", "scale"),
method = "lda",
metric = "Accuracy",                  # Specify which metric to optimize
trControl = fitControl)
fit.lda.cv
fit.lda.cv$finalModel
confusionMatrix(test$Group, predict(fit.lda.cv, test))
partimat(Group ~ TMG+CS, data = arenas, method = "lda", plot.matrix = T, imageplot = T, main = "Partition Plot")
pred.group = predict(fit.lda.cv, test)
pred.accuracy = round(mean(pred.group == test$Group)*100, 2)
pred.accuracy
View(X)
names(fit.lda.cv)
fit.lda.cv$modelInfo
fit.lda.cv$metric
fit.lda.cv$Accuracy
fit.lda.cv$results
fit.lda.cv$method
fit.lda.cv
fit.lda.cv$finalModel
knitr::opts_chunk$set(echo = TRUE)
print(fit.lda.cv)
knitr::opts_chunk$set(echo = TRUE)
arenas <- read.csv("arenas.csv", header = T, skip = ",")
arenas$Group <- as.factor(arenas$Group)
str(arenas)                                                             # estructura del dataframe
# Balance de Grupos
table(arenas$Group)
X <- arenas[, -3]
group <- as.factor(arenas[, 3])
Y <- as.matrix(arenas[, 1:2])
result <- manova(Y ~ group)
test_Wilks <- summary(result, test = "Wilks")
test_Wilks
fit.lda <- lda(formula = group ~ ., data = X)
fit.lda
plot(fit.lda)
predictions <- predict(fit.lda, X)
table(group, predictions$class)
library(MASS)                       # lda, ldahist functions
library(MVN)                        # mvn: outliers multi-variable, normalidad multi-variable
library(caret)                      # confusionMatrix, train functions
library(PerformanceAnalytics)       # chart.Correlation function
library(klaR)                       # partimat function (final plot)
library(kableExtra)
fit.lda <- lda(formula = group ~ ., data = X)
fit.lda
plot(fit.lda)
predictions <- predict(fit.lda, X)
table(group, predictions$class)
names(fit.lda)
fit.lda$svd
fit.lda$scaling
fit.lda$call
fit.lda$xlevels
fit.lda$terms
help(lda)
groupmean <- (fit.lda$prior %*% fit.lda$means)
constant <- (groupmean %*% fit.lda$scaling)
constant
fitControl <- trainControl(# 10-fold CV
method = "repeatedcv",
number = 10,                         # number of folds
repeats = 3,
allowParallel = TRUE                 # Parallel processing
)
# LDA
fit.lda.cv <- train(Group ~ TMG+CS,
data = arenas,
preProc = c("center", "scale"),
method = "lda",
metric = "Accuracy",                  # Specify which metric to optimize
trControl = fitControl
)
print(fit.lda.cv)
fit.lda.cv$finalModel
names(fit.lda.cv)
fit.lda.cv$coefnames
fit.lda.cv$modelInfo
fit.lda.cv$finalModel
??predict
fit.lda$metrics[c('ER', 'Sens','Spec')]
plot(fit.lda, type = "b")
??lda
plot.lda(fit.lda, dimen = 2, type = "b")
library(MASS)
plot.lda(fit.lda, dimen = 2, type = "b")
plot(fit.lda, dimen = 2, type = "b")
??plot
