caret::knn
knn3()
??confusionMatrix
install.packages("pROC")
knitr::opts_chunk$set(echo = TRUE)
library(ROCR)           # ROC Curve
library(pROC)           # Plot ROC Curve
library(tidyverse)
library(dplyr)
library(Amelia)         # missmap function
library(ModelMetrics)
library(caTools)
library(caret)          # excercise 5, train, confusionMatrix fucntions
library(kableExtra)
rain_data <- read.csv("RainSeattle2016.csv", header=T, na.strings = c(""))
str(rain_data)
rain_df <- subset(rain_data, select=c(1,3,4,5,7,8,9,10,11,12,13))
head(rain_df)
rain_df$Rain <- factor(rain_df$Rain)
rain_df$Season <- factor(rain_df$Season, ordered = FALSE)
rain_df$DATE <- as.Date(rain_df$DATE,'%m/%d/%Y')
str(rain_df)
inTrain <- createDataPartition(y = rain_df$Rain, p = 0.7, list = FALSE)
training <- rain_df[inTrain,]; testing <- rain_df[-inTrain,]
dim(training); dim(testing)
table(training$Rain); table(testing$Rain)
fitControl <- trainControl(# 10-fold CV
method = "repeatedcv",
number = 10,                       # number of folds
repeats = 3,                       # number of complete sets of folds to compute
classProbs = TRUE,                 # Evaluate performance using the following function
summaryFunction = twoClassSummary,
savePredictions = T,               # for ROC
allowParallel = TRUE               # Parallel processing
)
# Logistic Regression
knn.fit <- train(Rain ~ Season+TMAX+TMIN+WSF5,
data = training,
preProc = c("center", "scale"),
method = "knn",
metric = "ROC",                               # Specify which metric to optimize
tuneLength = 10,
trControl = fitControl
)
print(knn.fit, digits = 3)
knn.fit <- train(Rain ~ Season+TMAX+TMIN+WSF5,
data = training,
preProc = c("center", "scale"),
method = "knn",
metric = "ROC",                               # Specify which metric to optimize
tuneLength = 10,
trControl = fitControl
)
rain_df$Season <- character(rain_df$Season)
rain_df$Season <- as.character(rain_df$Season)
knn.fit <- train(Rain ~ Season+TMAX+TMIN+WSF5,
data = training,
preProc = c("center", "scale"),
method = "knn",
metric = "ROC",                               # Specify which metric to optimize
tuneLength = 10,
trControl = fitControl
)
View(rain_df)
rain_df$Season <- as.factor(rain_df$Season)
str(rain_df)
inTrain <- createDataPartition(y = rain_df$Rain, p = 0.7, list = FALSE)
training <- rain_df[inTrain,]; testing <- rain_df[-inTrain,]
dim(training); dim(testing)
table(training$Rain); table(testing$Rain)
fitControl <- trainControl(# 10-fold CV
method = "repeatedcv",
number = 10,                       # number of folds
repeats = 3,                       # number of complete sets of folds to compute
classProbs = TRUE,                 # Evaluate performance using the following function
summaryFunction = twoClassSummary,
savePredictions = T,               # for ROC
allowParallel = TRUE               # Parallel processing
)
# Logistic Regression
knn.fit <- train(Rain ~ Season+TMAX+TMIN+WSF5,
data = training,
preProc = c("center", "scale"),
method = "knn",
metric = "ROC",                               # Specify which metric to optimize
tuneLength = 10,
trControl = fitControl
)
View(rain_df)
rain_df$Rain <- ifelse(rain_df$Rain == 1, "Yes", "No")
rain_df$Rain <- as.factor(rain_df$Rain)
rain_df$Season <- as.factor(rain_df$Season)
View(rain_df)
inTrain <- createDataPartition(y = rain_df$Rain, p = 0.7, list = FALSE)
training <- rain_df[inTrain,]; testing <- rain_df[-inTrain,]
dim(training); dim(testing)
table(training$Rain); table(testing$Rain)
fitControl <- trainControl(# 10-fold CV
method = "repeatedcv",
number = 10,                       # number of folds
repeats = 3,                       # number of complete sets of folds to compute
classProbs = TRUE,                 # Evaluate performance using the following function
summaryFunction = twoClassSummary,
savePredictions = T,               # for ROC
allowParallel = TRUE               # Parallel processing
)
# Logistic Regression
knn.fit <- train(Rain ~ Season+TMAX+TMIN+WSF5,
data = training,
preProc = c("center", "scale"),
method = "knn",
metric = "ROC",                               # Specify which metric to optimize
tuneLength = 10,
trControl = fitControl
)
# Print results
print(knn.fit, digits = 3)
print(knn.fit$finalModel, digits=3)
plot(knn.fit)
pred <- predict(knn.fit, newdata = testing)
confusionMatrix(pred, testing$Rain, positive = "Yes")
knnPredict <- predict(knn.fit, newdata = testing, type = "prob")
knnROC <- roc(testing$Rain, knnPredict[, "Down"], levels = rev(testing$Rain))
knnPredict <- predict(knn.fit, newdata = testing, type = "prob")
knnPredict
knnPredict <- predict(knn.fit, newdata = testing, type = "response")
knnPredict <- predict(knn.fit, newdata = testing, type = "raw")
knnROC <- roc(testing$Rain, knnPredict[, "Down"], levels = rev(testing$Rain))
knnPredict
knnPredict <- predict(knn.fit, newdata = testing, type = "raw")
knnROC <- roc(testing$Rain, knnPredict, levels = rev(testing$Rain))
knnROC <- roc(testing$Rain, knnPredict[, "Yes"], levels = rev(testing$Rain))
knnROC <- roc(testing$Rain, knnPredict[, "Rain"], levels = rev(testing$Rain))
View(testing)
??roc
pred
knnROC <- roc(testing$Rain, knnPredict[, "Yes"], levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, knnPredict$Rain, levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, knnPredict, levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, pred, levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, pred$Rain, levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, knnPredict["Yes", "No"], levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, knnPredict[c("Yes", "No")], levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, knnPredict[, ""], levels=c("Yes", "No"))
knnROC <- roc(testing$Rain, knnPredict[, "No"], levels=c("Yes", "No"))
ROCRPred <- prediction(predicted, testing$Rain)
ROCRPred <- prediction(pred, testing$Rain)
knnPredict <- predict(knn.fit, newdata = testing , type="prob")
ROCRPred <- prediction(knnPredict, testing$Rain)
knnPredict <- predict(knn.fit, newdata = testing, type="prob")
View(knnPredict)
knnPredict <- predict(knn.fit, newdata = testing, type="raw")
ROCRPred <- prediction(knnPredict, testing$Rain)
testing$Rain
knnPredict
ROCRPred <- prediction(knnPredict, testing$Rain)
names(knnPredict)
View(training)
??subset
knitr::opts_chunk$set(echo = TRUE)
rain_df.sub <- subset(rain_df, select=c(Rain, TMAX, WSF5))
View(rain_df.sub)
decisionplot(knn.fit, rain_df.sub, class = "Rain", main = "kNN (1)")
decisionplot <- function(model, data, class = NULL, predict_type = "class",
resolution = 100, showgrid = TRUE, ...) {
if(!is.null(class)) cl <- data[,class] else cl <- 1
data <- data[,1:2]
k <- length(unique(cl))
plot(data, col = as.integer(cl)+1L, pch = as.integer(cl)+1L, ...)
# make grid
r <- sapply(data, range, na.rm = TRUE)
xs <- seq(r[1,1], r[2,1], length.out = resolution)
ys <- seq(r[1,2], r[2,2], length.out = resolution)
g <- cbind(rep(xs, each=resolution), rep(ys, time = resolution))
colnames(g) <- colnames(r)
g <- as.data.frame(g)
### guess how to get class labels from predict
### (unfortunately not very consistent between models)
p <- predict(model, g, type = predict_type)
if(is.list(p)) p <- p$class
p <- as.factor(p)
if(showgrid) points(g, col = as.integer(p)+1L, pch = ".")
z <- matrix(as.integer(p), nrow = resolution, byrow = TRUE)
contour(xs, ys, z, add = TRUE, drawlabels = FALSE,
lwd = 2, levels = (1:(k-1))+.5)
invisible(z)
}
decisionplot(knn.fit, rain_df.sub, class = "Rain", main = "kNN (1)")
library(caret)
knn3.fit <- knn3(Rain ~ ., data = rain_df, k = 1)
decisionplot(knn3.fit, rain_df.sub, class = "Rain", main = "kNN (1)")
rain_df.sub <- subset(rain_df, select=c(Rain, TMAX, WSF5))
knn3.fit <- knn3(Rain ~ ., data = rain_df.sub, k = 1)
decisionplot(knn3.fit, rain_df.sub, class = "Rain", main = "kNN (1)")
str(rain_df.sub)
iris
str(iris)
View(rain_df.sub)
plot(rain_df.sub[, 2:3], col = rain_df.sub[, 1])
decisionplot(knn3.fit, rain_df.sub, class = "Rain", main = "kNN (1)")
decisionplot(knn3.fit, rain_df.sub, class = "class", main = "kNN (1)")
View(rain_df.sub)
rain_df.sub <- subset(rain_df, select=c(TMAX, WSF5, Rain))
View(rain_df.sub)
knn3.fit <- knn3(Rain ~ TMAX+WSF5, data = rain_df.sub, k = 1)
plot(knn3.fit)
decisionplot(knn3.fit, rain_df.sub, class = "Rain", main = "kNN (1)")
knn3.fit10 <- knn3(Rain ~ TMAX+WSF5, data = rain_df.sub, k = 10)
decisionplot(knn3.fit10, rain_df.sub, class = "Rain", main = "kNN (10)")
